{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "* TF --> Term Frequency\n",
    "* IDF --> Inverse Document Frequency\n",
    "* We used this method to highlight the importance of the particular word in the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ TF = count of particular word in sentence / Total number of words in the sentence\n",
    "+ IDF = log(Number of sentences / Number of sentences containing that word)\n",
    "* TF*IDF = This is the final value assign to particular word according to its importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"\"\"Kindness towards nature, animals and other people has the ability to transform the world and make it a beautiful place for living. But, it is also important to remember that kindness towards you is also essential for personal growth.\n",
    "\n",
    "Kindness is basically being polite, compassionate and thoughtful. Every religion and faith teaches its followers to be kind. Most importantly, kindness must not limit to humans but also to every living creature.\n",
    "\n",
    "Even nature has its own way of showing kindness. For instance, the trees grow fruits for us and provide us with shade. One must not see kindness as a core value but as a fundamental behavioural element. When you are kind to your loved ones, you create a stable base.\n",
    "\n",
    "As people are becoming more self-centred today, we must learn kindness. We must try to integrate it into ourselves. You might not know how a small act of kindness can bring about a change in someone’s life. So, be kind always.\n",
    "\n",
    "Kindness Always Wins\n",
    "There is no doubt that kindness always wins and it has been proven time and again by people. Sid is a greedy man who does not share his wealth with anyone, not even his family members.\n",
    "\n",
    "He also does not pay his workers well. One day, he loses his bag of gold coins and loses his temper. Everyone helps him out to search for it but no one finds it. Finally, his worker’s little son finds the bag.\n",
    "\n",
    "Upon checking the bag, he sees all the coins are there. But, his greed makes him play a trick on the poor worker. He claims that there were more coins in the bag and the worker stole them.\n",
    "\n",
    "The issue goes to the court and the judge confirms from Sid whether his bag had more coins to which he agrees. So, the judge rules out that as Sid’s bag had more coins, the bag which the worker’s son found is not his.\n",
    "\n",
    "Therefore, the bag gets handed to the worker as no one else claims it. Consequently, you see how the worker’s son act of kindness won and paid him well. On the other hand, how Sid’s greediness resulted in his loss only.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub(\"[^A-Za-z]\",\" \",sentences[i])\n",
    "    review = review.lower()\n",
    "    words = review.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(words)\n",
    "    corpus.append(review) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31471818, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.31471818],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.25181806,\n",
       "        0.        ],\n",
       "       [0.        , 0.37699187, 0.        , ..., 0.        , 0.26264082,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(corpus).toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
