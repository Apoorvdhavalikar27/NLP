{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP : Convert words to numbers and get Embedded Vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding,Dense,Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "reviews = [\n",
    "    \n",
    "    'nice food',\n",
    "    'very good food',\n",
    "    'delicious cusine',\n",
    "    'nice hotel',\n",
    "    'poor test',\n",
    "    'bad service',\n",
    "    'bad staff',\n",
    "    'worst food'\n",
    "]\n",
    "\n",
    "labels = np.array([1,1,1,1,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word to vector conversion using one_hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 30]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets convert reviews in to number using one hot encoding\n",
    "vocabulary_size = 40\n",
    "one_hot('nice food',vocabulary_size)\n",
    "# this method assign unique values between 0,40 i.e. size of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[18, 30],\n",
       " [29, 10, 30],\n",
       " [23, 20],\n",
       " [18, 33],\n",
       " [22, 13],\n",
       " [26, 22],\n",
       " [26, 15],\n",
       " [8, 30]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_reviews = [one_hot(i,vocabulary_size) for i in reviews ]\n",
    "encoded_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad zeros to achive same length of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18, 30,  0],\n",
       "       [29, 10, 30],\n",
       "       [23, 20,  0],\n",
       "       [18, 33,  0],\n",
       "       [22, 13,  0],\n",
       "       [26, 22,  0],\n",
       "       [26, 15,  0],\n",
       "       [ 8, 30,  0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We pad 0 to sequence to get fix size vector\n",
    "max_seq_len = 3\n",
    "padding_reviews = pad_sequences(encoded_reviews,max_seq_len,padding='post')\n",
    "padding_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padding_reviews\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Embedding  vector?\n",
    "# When we train the model on data , as a side effect embedding vectors gets generated\n",
    "# Embedding vectors are nothing buts the weightes used in embedding layer on NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models and get weightes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our embeded vector size\n",
    "embeded_vector_size = 4\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size,embeded_vector_size,input_length = max_seq_len, name = 'embedding_layer'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2164bc17460>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=50,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 858ms/step - loss: 0.6039 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6039316654205322, 1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights of Embedding layer Nothing but our Embedded Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03384051,  0.00351452, -0.0665306 , -0.0770149 ],\n",
       "        [-0.01352127,  0.04585799, -0.04243093, -0.04240325],\n",
       "        [-0.01363826,  0.04615723, -0.03486953, -0.0316488 ],\n",
       "        [ 0.03666026,  0.0230563 ,  0.04383364, -0.02502699],\n",
       "        [-0.00818635,  0.01206272, -0.02288911, -0.03219646],\n",
       "        [ 0.03890054,  0.00865523, -0.02347723, -0.02095464],\n",
       "        [-0.02427973,  0.0224246 ,  0.01259789,  0.00755932],\n",
       "        [ 0.04455408,  0.03521914, -0.04374627, -0.02639772],\n",
       "        [-0.00245443, -0.05883659,  0.06196056,  0.04493309],\n",
       "        [ 0.04143638, -0.02915286,  0.0222996 , -0.01149797],\n",
       "        [ 0.00954473,  0.08181886,  0.05412078, -0.01149709],\n",
       "        [-0.03174105, -0.02863827,  0.01150708,  0.03001643],\n",
       "        [-0.04593758, -0.03296578,  0.04892499, -0.04888413],\n",
       "        [-0.06420647, -0.07558623, -0.05121271,  0.04137637],\n",
       "        [ 0.03444702, -0.0088213 , -0.01221281, -0.03687661],\n",
       "        [-0.07297999, -0.0813506 , -0.03264644,  0.01776345],\n",
       "        [-0.01431925,  0.0314979 , -0.01282463,  0.03844571],\n",
       "        [ 0.04088381, -0.03312659, -0.0018029 , -0.03510897],\n",
       "        [ 0.03113315,  0.09302626, -0.0277359 , -0.09367346],\n",
       "        [ 0.01911515,  0.03111582, -0.02426546,  0.00152036],\n",
       "        [ 0.07934147,  0.02339018,  0.07689828, -0.01730031],\n",
       "        [ 0.04876507, -0.02926954, -0.02709112, -0.00676601],\n",
       "        [-0.09553239, -0.03966352, -0.06161185,  0.07134329],\n",
       "        [ 0.03838556,  0.0225484 , -0.01800498, -0.09743129],\n",
       "        [-0.00020932, -0.00906707, -0.03882519, -0.01509701],\n",
       "        [-0.02090337,  0.00795067,  0.00398009, -0.00583155],\n",
       "        [-0.06315855, -0.0538126 ,  0.0380924 ,  0.04279554],\n",
       "        [-0.02330664,  0.02042172, -0.02820302,  0.0388049 ],\n",
       "        [-0.02661514,  0.01572189,  0.00776343, -0.02525083],\n",
       "        [ 0.03700558,  0.04946881, -0.07685229, -0.06264975],\n",
       "        [-0.0674272 , -0.05192318,  0.08319729,  0.00082193],\n",
       "        [-0.03682231,  0.00922077, -0.04738605, -0.04335984],\n",
       "        [ 0.00288052, -0.02868718,  0.00045667, -0.01950686],\n",
       "        [ 0.01880882,  0.0153837 ,  0.05208196, -0.07981732],\n",
       "        [-0.03560668, -0.03902002,  0.04147773, -0.04521459],\n",
       "        [-0.01021565,  0.01813403,  0.04526651,  0.0270266 ],\n",
       "        [ 0.04689947,  0.01918968,  0.02565977, -0.01328914],\n",
       "        [ 0.00755886, -0.03677364,  0.02894128, -0.03919785],\n",
       "        [-0.00894712,  0.04450402, -0.02082815, -0.01153319],\n",
       "        [ 0.02988089,  0.00919112, -0.00109415, -0.04965175]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This are the embedding vectors genrated as by product of model training\n",
    "embedded_vectors = model.get_layer('embedding_layer').get_weights()\n",
    "embedded_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare two vectors of same sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01352127  0.04585799 -0.04243093 -0.04240325]\n",
      "[-0.01363826  0.04615723 -0.03486953 -0.0316488 ]\n"
     ]
    }
   ],
   "source": [
    "# second review 'very good food'\n",
    "print(embedded_vectors[0][1])\n",
    "# third review  'delicious cusine'\n",
    "print(embedded_vectors[0][2])\n",
    "# They are nearly similiar "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
